{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRANGLING EFFORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrangling process involved gathering,assessing, cleaning and exploring three datasets. These include \n",
    "\n",
    "- 'twitter-archive-enhanced.csv'\n",
    "- 'image-predictions.tsv'\n",
    "- 'tweet-json.txt'\n",
    "\n",
    "### GATHERING DATA\n",
    "- For this aspect of wrangling, different methods were required to gather each dataset.\n",
    "\n",
    "    #### twitter-archive-enhanced.csv\n",
    "    - I acquired the twitter archive dataset by directly downloading it then read it into a pandas dataframe after importing the pandas module.\n",
    "    \n",
    "    #### image-predictions.tsv\n",
    "    - The image predictions dataset needed to be gotten from the internet. To do this,  I used Requests library to download it using a url by importing the necessary modules (requests and os). After this, I read it into a dataframe.\n",
    "    \n",
    "    #### tweet-json.txt\n",
    "    - This required me getting it from twitter using their API but I couldn't get the developer account so I directly downloaded it and read it into a dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSESSING DATA\n",
    "- For this, I was to detect at least <b>eight quality issues</b> and <b>two tidiness issues</b> using both visual and programmatic assessment. Below are the Quality and Tidiness issues I detected from the three datasets while paying attention to specific key points such as original ratings in the data i.e no retweets.\n",
    "\n",
    "### Quality issues\n",
    "#### Twitter archive data\n",
    "1. Wrong datatypes of some data\n",
    "\n",
    "\n",
    "2. Unneccesary data\n",
    "\n",
    "\n",
    "3. Source column is duplicated in both tweet json and twitter archive file\n",
    "\n",
    "\n",
    "4. Name column contains non-valid names\n",
    "\n",
    "\n",
    "5. Source column as a link not as a category\n",
    "\n",
    "\n",
    "6. Retweets in the dataframe\n",
    "\n",
    "\n",
    "#### Image predictions\n",
    "\n",
    "\n",
    "7. Some columns contain inconsistent data\n",
    "\n",
    "\n",
    "#### Json data\n",
    "\n",
    "\n",
    "8. Id column is not similar to the id columns in other dataframes\n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    "1. Merge datasets \n",
    "\n",
    "\n",
    "2. Expanded urls have multiple variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEANING DATA\n",
    "- This involved cleaning the data according to the rules of tidy data. Prior to cleaning, I made a copy of the original data. I used the ,<b> Define, Code, Test</b> method throughout the cleaning process to define what problem I was tackling, write code to solve it and finally check the results. I was guided by the quality and tidiness issues gotten earlier during this process. \n",
    "\n",
    "- Following this process, I merged the cleaned dataframes into one master dataframe and stored it in a csv file called <b>'twitter_archive_master.csv'</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS AND VISUALIZATION\n",
    "- After cleaning and storing the data, I proceeded to analyse and visualize the data to gather at least <b>three insights </b> and <b>one visualization</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
